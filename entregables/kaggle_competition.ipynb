{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competencia de Kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "# Modelos de clasificación\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, VotingClassifier, StackingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Ignorar warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el dataset de entrenamiento\n",
    "URL_TRAIN = 'https://raw.githubusercontent.com/DiploDatos/AprendizajeSupervisado/master/Pr%C3%A1ctico/diabetes_prediction_dataset_train-labeled.csv'\n",
    "TRAIN_DF = pd.read_csv(URL_TRAIN)\n",
    "\n",
    "# Cargamos el dataset de test\n",
    "URL_TEST = 'https://raw.githubusercontent.com/DiploDatos/AprendizajeSupervisado/master/Pr%C3%A1ctico/diabetes_prediction_dataset_test.csv'\n",
    "TEST_DF = pd.read_csv(URL_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones auxiliares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBAR MODELOS CON PARÁMETROS POR DEFECTO Y AJUSTADOS\n",
    "\n",
    "models = {\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(random_state=42),\n",
    "        'params': {}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {}\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model': GradientBoostingClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'loss': ['log_loss', 'exponential'],\n",
    "            'learning_rate': [0.1,  0.01],\n",
    "            'n_estimators': [100, 200],\n",
    "            'criterion': ['friedman_mse', 'squared_error'],\n",
    "            'max_depth': [3, 5]\n",
    "        }\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'model': AdaBoostClassifier(random_state=42),\n",
    "        'params': {}\n",
    "    },\n",
    "    'Bagging': {\n",
    "        'model': BaggingClassifier(random_state=42),\n",
    "        'params': {}\n",
    "    },\n",
    "    'HistGradientBoosting': {\n",
    "        'model': HistGradientBoostingClassifier(random_state=42),\n",
    "        'params': {}\n",
    "    },\n",
    "    'SVC': {\n",
    "        'model': SVC(random_state=42),\n",
    "        'params': {}\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=42),\n",
    "        'params': {}\n",
    "    },\n",
    "    'MLP': {\n",
    "        'model': MLPClassifier(random_state=42),\n",
    "        'params': {}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBClassifier(random_state=42),\n",
    "        'params': {}\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def try_default_models(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    trained_models = pd.DataFrame(columns=['model', 'train_acc', 'train_prec',\n",
    "                                  'train_rec', 'train_f1', 'test_acc', 'test_prec', 'test_rec', 'test_f1'])\n",
    "    for name, model in models.items():\n",
    "        print(f'Modelo {name}')\n",
    "\n",
    "        clf = model['model']\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = clf.predict(X_train)\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "\n",
    "        trained_models = trained_models._append({\n",
    "            'model': name,\n",
    "            'train_acc': accuracy_score(y_train, y_train_pred),\n",
    "            'train_prec': precision_score(y_train, y_train_pred),\n",
    "            'train_rec': recall_score(y_train, y_train_pred),\n",
    "            'train_f1': f1_score(y_train, y_train_pred),\n",
    "            'test_acc': accuracy_score(y_test, y_test_pred),\n",
    "            'test_prec': precision_score(y_test, y_test_pred),\n",
    "            'test_rec': recall_score(y_test, y_test_pred),\n",
    "            'test_f1': f1_score(y_test, y_test_pred)\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    return trained_models\n",
    "\n",
    "\n",
    "def try_adjusted_model(X, y, clf_name):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    clf_params = models[clf_name]['params']\n",
    "    clf = models[clf_name]['model']\n",
    "    gv = GridSearchCV(clf, clf_params, cv=5, n_jobs=-1)\n",
    "    gv.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = gv.predict(X_train)\n",
    "    y_test_pred = gv.predict(X_test)\n",
    "\n",
    "    return {\n",
    "        'model': clf_name,\n",
    "        'best_params': gv.best_params_,\n",
    "        'train_acc': accuracy_score(y_train, y_train_pred),\n",
    "        'train_prec': precision_score(y_train, y_train_pred),\n",
    "        'train_rec': recall_score(y_train, y_train_pred),\n",
    "        'train_f1': f1_score(y_train, y_train_pred),\n",
    "        'test_acc': accuracy_score(y_test, y_test_pred),\n",
    "        'test_prec': precision_score(y_test, y_test_pred),\n",
    "        'test_rec': recall_score(y_test, y_test_pred),\n",
    "        'test_f1': f1_score(y_test, y_test_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÁLCULO DE ACCURACY DE UN MODELO PARA K FOLDS\n",
    "\n",
    "def get_accuracy(clf, X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    accuracies = []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAMOS OUTPUT DE SALIDA\n",
    "\n",
    "def generate_output(clf, filename=None):\n",
    "    if filename is None:\n",
    "        filename = clf.__class__.__name__\n",
    "\n",
    "    # Cargamos el dataset de test\n",
    "    test_df = TEST_DF.copy()\n",
    "\n",
    "    # Preprocesamiento\n",
    "    patient_id = test_df['patient']\n",
    "    X_test = test_df.drop(columns=['diabetes', 'patient'])\n",
    "\n",
    "    for col in [\"gender\", \"smoking_history\"]:\n",
    "        X_test[col] = X_test[col].astype(str)\n",
    "        X_test[col] = LabelEncoder().fit_transform(X_test[col])\n",
    "\n",
    "    cols = X_test.columns\n",
    "    X_test = StandardScaler().fit_transform(X_test)\n",
    "    X_test = pd.DataFrame(X_test, columns=cols)\n",
    "\n",
    "    # Predicción\n",
    "    test_pred = np.int64(clf.predict(X_test))\n",
    "    submission = pd.DataFrame(list(zip(patient_id, test_pred)), columns=[\n",
    "                              'patient', 'diabetes'])\n",
    "    submission.to_csv(f'output/{filename}.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Decision Tree\n",
      "Modelo Random Forest\n",
      "Modelo Gradient Boosting\n",
      "Modelo AdaBoost\n",
      "Modelo Bagging\n",
      "Modelo HistGradientBoosting\n",
      "Modelo SVC\n",
      "Modelo KNN\n",
      "Modelo Logistic Regression\n",
      "Modelo MLP\n",
      "Modelo XGBoost\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_prec</th>\n",
       "      <th>train_rec</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_prec</th>\n",
       "      <th>test_rec</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HistGradientBoosting</td>\n",
       "      <td>0.973474</td>\n",
       "      <td>0.992069</td>\n",
       "      <td>0.694586</td>\n",
       "      <td>0.817093</td>\n",
       "      <td>0.972053</td>\n",
       "      <td>0.980216</td>\n",
       "      <td>0.681676</td>\n",
       "      <td>0.804131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.972013</td>\n",
       "      <td>0.976170</td>\n",
       "      <td>0.688724</td>\n",
       "      <td>0.807633</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>0.973381</td>\n",
       "      <td>0.686054</td>\n",
       "      <td>0.804842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.972237</td>\n",
       "      <td>0.987731</td>\n",
       "      <td>0.683017</td>\n",
       "      <td>0.807587</td>\n",
       "      <td>0.971947</td>\n",
       "      <td>0.981917</td>\n",
       "      <td>0.679174</td>\n",
       "      <td>0.802957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.972329</td>\n",
       "      <td>0.981530</td>\n",
       "      <td>0.688570</td>\n",
       "      <td>0.809355</td>\n",
       "      <td>0.971684</td>\n",
       "      <td>0.965759</td>\n",
       "      <td>0.687930</td>\n",
       "      <td>0.803506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.975803</td>\n",
       "      <td>0.989873</td>\n",
       "      <td>0.723739</td>\n",
       "      <td>0.836140</td>\n",
       "      <td>0.971632</td>\n",
       "      <td>0.959272</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.804214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.999197</td>\n",
       "      <td>0.999378</td>\n",
       "      <td>0.991208</td>\n",
       "      <td>0.995276</td>\n",
       "      <td>0.970158</td>\n",
       "      <td>0.954225</td>\n",
       "      <td>0.677924</td>\n",
       "      <td>0.792687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.996103</td>\n",
       "      <td>0.946321</td>\n",
       "      <td>0.970574</td>\n",
       "      <td>0.969368</td>\n",
       "      <td>0.924103</td>\n",
       "      <td>0.692933</td>\n",
       "      <td>0.791994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.964303</td>\n",
       "      <td>0.980132</td>\n",
       "      <td>0.593552</td>\n",
       "      <td>0.739360</td>\n",
       "      <td>0.963947</td>\n",
       "      <td>0.966327</td>\n",
       "      <td>0.592245</td>\n",
       "      <td>0.734393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.969684</td>\n",
       "      <td>0.943160</td>\n",
       "      <td>0.685948</td>\n",
       "      <td>0.794249</td>\n",
       "      <td>0.961526</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.630394</td>\n",
       "      <td>0.733892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.960184</td>\n",
       "      <td>0.868315</td>\n",
       "      <td>0.628567</td>\n",
       "      <td>0.729241</td>\n",
       "      <td>0.960895</td>\n",
       "      <td>0.867698</td>\n",
       "      <td>0.631645</td>\n",
       "      <td>0.731089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.999197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990591</td>\n",
       "      <td>0.995273</td>\n",
       "      <td>0.954421</td>\n",
       "      <td>0.726095</td>\n",
       "      <td>0.736085</td>\n",
       "      <td>0.731056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  train_acc  train_prec  train_rec  train_f1  \\\n",
       "0   HistGradientBoosting   0.973474    0.992069   0.694586  0.817093   \n",
       "1               AdaBoost   0.972013    0.976170   0.688724  0.807633   \n",
       "2      Gradient Boosting   0.972237    0.987731   0.683017  0.807587   \n",
       "3                    MLP   0.972329    0.981530   0.688570  0.809355   \n",
       "4                XGBoost   0.975803    0.989873   0.723739  0.836140   \n",
       "5          Random Forest   0.999197    0.999378   0.991208  0.995276   \n",
       "6                Bagging   0.995105    0.996103   0.946321  0.970574   \n",
       "7                    SVC   0.964303    0.980132   0.593552  0.739360   \n",
       "8                    KNN   0.969684    0.943160   0.685948  0.794249   \n",
       "9    Logistic Regression   0.960184    0.868315   0.628567  0.729241   \n",
       "10         Decision Tree   0.999197    1.000000   0.990591  0.995273   \n",
       "\n",
       "    test_acc  test_prec  test_rec   test_f1  \n",
       "0   0.972053   0.980216  0.681676  0.804131  \n",
       "1   0.972000   0.973381  0.686054  0.804842  \n",
       "2   0.971947   0.981917  0.679174  0.802957  \n",
       "3   0.971684   0.965759  0.687930  0.803506  \n",
       "4   0.971632   0.959272  0.692308  0.804214  \n",
       "5   0.970158   0.954225  0.677924  0.792687  \n",
       "6   0.969368   0.924103  0.692933  0.791994  \n",
       "7   0.963947   0.966327  0.592245  0.734393  \n",
       "8   0.961526   0.878049  0.630394  0.733892  \n",
       "9   0.960895   0.867698  0.631645  0.731089  \n",
       "10  0.954421   0.726095  0.736085  0.731056  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = TRAIN_DF.copy()\n",
    "\n",
    "# Separamos la variable objetivo\n",
    "patientId = train_df.patient\n",
    "y = train_df.diabetes\n",
    "X = train_df.drop(columns=['diabetes', 'patient'])\n",
    "\n",
    "# Encoding de variables categóricas\n",
    "for col in [\"gender\", \"smoking_history\"]:\n",
    "    X[col] = X[col].astype(str)\n",
    "    X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "# Escalamos las variables\n",
    "X_names = X.columns\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X = pd.DataFrame(X, columns=X_names)\n",
    "\n",
    "# Probamos los modelos por defecto\n",
    "trained_models = try_default_models(X, y)\n",
    "trained_models = trained_models.sort_values(\n",
    "    by='test_acc', ascending=False).reset_index(drop=True)\n",
    "display(trained_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_prec</th>\n",
       "      <th>train_rec</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_prec</th>\n",
       "      <th>test_rec</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.972237</td>\n",
       "      <td>0.987731</td>\n",
       "      <td>0.683017</td>\n",
       "      <td>0.807587</td>\n",
       "      <td>0.971947</td>\n",
       "      <td>0.981917</td>\n",
       "      <td>0.679174</td>\n",
       "      <td>0.802957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  best_params  train_acc  train_prec  train_rec  train_f1  \\\n",
       "0  Gradient Boosting          NaN   0.972237    0.987731   0.683017  0.807587   \n",
       "\n",
       "   test_acc  test_prec  test_rec   test_f1  \n",
       "0  0.971947   0.981917  0.679174  0.802957  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros para Gradient Boosting: {'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Probamos ajustar el modelo de Gradient Boosting\n",
    "gb_model = try_adjusted_model(X, y, 'Gradient Boosting')\n",
    "display(pd.DataFrame(gb_model, index=[0]))\n",
    "\n",
    "print(f'Mejores parámetros para Gradient Boosting: {gb_model[\"best_params\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La accuracy para Gradient Boosting con 10 splits es: 0.9719684210526316 +/- 0.0019174371168184138\n"
     ]
    }
   ],
   "source": [
    "# Miremos la accuracy que obtenemos con el modelo ajustado de Gradient Boosting para KFold con 10 splits\n",
    "accuracies = get_accuracy(GradientBoostingClassifier(\n",
    "    **gb_model['best_params']), X, y, n_splits=10)\n",
    "print(f'La accuracy para Gradient Boosting con 10 splits es: {\n",
    "      np.mean(accuracies)} +/- {np.std(accuracies)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos el output\n",
    "gb_model_adj = GradientBoostingClassifier(**gb_model['best_params'])\n",
    "gb_model_adj.fit(X, y)\n",
    "generate_output(gb_model_adj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
